{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf36e4d-ac8e-4c0c-849b-72348c00c26a",
   "metadata": {},
   "source": [
    "# ch 4. Tokenize\n",
    "자연어 처리에서 텍스트 데이터를 corpus(코퍼스, 말뭉치)라고 부릅니다. 크롤링 시간에 수집했던 뉴스 기사들도 코퍼스라고 부를 수 있습니다. 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 합니다. (토큰해주는 기술 tokenizer)\n",
    "\n",
    "토큰은 컴퓨터가 텍스트를 처리하는 최소 의미 단위가 됩니다. 토큰화에는 여러 기법들이 있습니다. 딥러닝 등장 이전의 NLP에서는 주로 언어학 관점에서 정의한 최소 의미 단위인 형태소를 기준으로 토큰화를 했습니다. 하지만 최근 딥러닝 모델들은 데이터로부터 자연스럽게 토크나이저를 학습하는 subword 토큰화를 사용하며, 딥러닝을 이용한 NLP 시간에 배워보겠습니다.\n",
    "\n",
    "형태소 단위로 문장을 토큰화 해주는 기술을 형태소 분석기라고 부릅니다. 형태소 분석기는 언어학적으로 해석이 가능한 장점이 있습니다만, 고유명사나 신조어 대응이 어려운 한계가 있습니다. 이번 챕터에서는 기본적인 토큰화 기법들과 형태소 분석기를 실습해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a16dc3-6cb4-4e9e-9164-c57f1c4a018d",
   "metadata": {},
   "source": [
    "## 공백 기준의 토큰화\n",
    "먼저 생각할 수 있는 가장 단순한 토큰화 기법은 공백을 기준으로 잘라내는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfdc189-69f8-46ab-b0e2-d510f75edfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '롯데 자이언츠의 거인 이대호(40)의 꿈이 무너져가고 있다. 이대호가 새해 40세 불혹(不惑)의 나이가 됐다. 불혹은 주위에서 어떤 일이 벌어져도 중심을 잃지 않고 자신만의 원칙을 지켜 나갈 수 있는 경지에 오르는 시기다. 이번 스토브리그에 롯데 구단에 걱정스러운 일이 벌어지고 있다. 그런데 이대호는 어떤 대외 활동도 하지 않고 침묵하며 조용히 개인 훈련에 집중하는 모습이다. 불혹이 돼서인가? 지난 2017년 1월24일이다. 벌써 5년의 시간이 흘렀다. 롯데의 프랜차이즈 스타 이대호가 일본프로야구 미국 메이저리그를 거쳐 고향팀 롯데로 돌아왔다. 그는 ‘조선의 4번타자’답게 단숨에 최고가 됐다. 삼성에서 FA가 된 최형우가 고향팀 KIA 타이거즈와 4년 계약을 하면서 기록한 총액 100억 원을 훨씬 넘어 150억 원에 롯데와 계약했다. 당시 인터뷰에서 이대호는 ‘메이저리그에서 열심히 노력해 꿈을 이루었다. 남은 것은 롯데로 돌아와 함께 우승을 하는 것이다. 마지막 소원이 롯데의 우승’이라고 밝혔다. 2001년 롯데에 2차 1순위로 입단해 2011시즌까지 11시즌 동안 이대호는 무려 225개의 홈런을 쏘아 올렸다. 그리고 2008~2011 시즌까지 4년 연속 롯데를 포스트시즌으로 이끌었으나 한국시리즈 우승을 못하고 일본 프로야구로 떠났다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da73e902-6a55-4968-a0ee-50475d404df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['롯데', '자이언츠의', '거인', '이대호(40)의', '꿈이', '무너져가고', '있다.', '이대호가', '새해', '40세', '불혹(不惑)의', '나이가', '됐다.', '불혹은', '주위에서', '어떤', '일이', '벌어져도', '중심을', '잃지', '않고', '자신만의', '원칙을', '지켜', '나갈', '수', '있는', '경지에', '오르는', '시기다.', '이번', '스토브리그에', '롯데', '구단에', '걱정스러운', '일이', '벌어지고', '있다.', '그런데', '이대호는', '어떤', '대외', '활동도', '하지', '않고', '침묵하며', '조용히', '개인', '훈련에', '집중하는', '모습이다.', '불혹이', '돼서인가?', '지난', '2017년', '1월24일이다.', '벌써', '5년의', '시간이', '흘렀다.', '롯데의', '프랜차이즈', '스타', '이대호가', '일본프로야구', '미국', '메이저리그를', '거쳐', '고향팀', '롯데로', '돌아왔다.', '그는', '‘조선의', '4번타자’답게', '단숨에', '최고가', '됐다.', '삼성에서', 'FA가', '된', '최형우가', '고향팀', 'KIA', '타이거즈와', '4년', '계약을', '하면서', '기록한', '총액', '100억', '원을', '훨씬', '넘어', '150억', '원에', '롯데와', '계약했다.', '당시', '인터뷰에서', '이대호는', '‘메이저리그에서', '열심히', '노력해', '꿈을', '이루었다.', '남은', '것은', '롯데로', '돌아와', '함께', '우승을', '하는', '것이다.', '마지막', '소원이', '롯데의', '우승’이라고', '밝혔다.', '2001년', '롯데에', '2차', '1순위로', '입단해', '2011시즌까지', '11시즌', '동안', '이대호는', '무려', '225개의', '홈런을', '쏘아', '올렸다.', '그리고', '2008~2011', '시즌까지', '4년', '연속', '롯데를', '포스트시즌으로', '이끌었으나', '한국시리즈', '우승을', '못하고', '일본', '프로야구로', '떠났다.']\n"
     ]
    }
   ],
   "source": [
    "tokens = sentence.split(\" \")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3559f-8872-4673-bd8f-555c761ee53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83b0328-292d-414b-9a9e-c383419efc5b",
   "metadata": {},
   "source": [
    "이렇게 공백을 기준으로 토큰을 만들게 되면 한국어의 특성상 조사를 떼어낼 수가 없습니다. 즉, \"이대호가\", \"이대호는\"과 같이 실제로는 비슷한 의미를 갖는 토큰을 전혀 다른 토큰으로 인식하게 됩니다. 토큰화가 제대로 이루어지지 않으면 제 아무리 고도화 된 AI 모델을 학습시킨다 하더라도 정확도를 기대할 수 없습니다.\n",
    "\n",
    "공백을 기준으로 잡는 것 외에도 온 점이나 쉼표를 기준으로 토큰화를 하는 기법들이 있지만, 마찬가지로 낮은 정확도로 인해 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1905d-c9b8-46a4-ad93-f28da0c8b410",
   "metadata": {},
   "source": [
    "## 형태소 분석기를 이용한 토큰화\n",
    "다음으로 형태소 분석기를 이용한 토큰화를 해보겠습니다. 가장 쉽게 사용할 수 있는 konlpy의 komoran을 사용하여 실습을 진행해보겠습니다. konlpy는 한국어 자연어 처리 라이브러리이고, komoran은 konlpy를 통해 이용할 수 있는 형태소 분석기 중 하나입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba10889-deba-4f38-aa66-9a3dbdf7b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885a11b2-92a9-4534-a3a5-facb697d7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('롯데 자이언츠', 'NNP'), ('의', 'JKG'), ('거인', 'NNP'), ('이대호', 'NNP'), ('(', 'SS'), ('40', 'SN'), (')', 'SS'), ('의', 'JKG'), ('꿈', 'NNG'), ('이', 'JKS'), ('무너지', 'VV'), ('어', 'EC'), ('가', 'VX'), ('고', 'EC'), ('있', 'VX'), ('다', 'EF'), ('.', 'SF'), ('이대호', 'NNP'), ('가', 'JKS'), ('새해', 'NNP'), ('40', 'SN'), ('세', 'NNB'), ('불혹', 'NNG'), ('(', 'SS'), ('不惑', 'SH'), (')', 'SS'), ('의', 'JKG'), ('나이', 'NNG'), ('가', 'JKS'), ('되', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('불혹', 'NNG'), ('은', 'JX'), ('주위', 'NNG'), ('에서', 'JKB'), ('어떤', 'MM'), ('일', 'NNG'), ('이', 'JKS'), ('벌어지', 'VV'), ('어도', 'EC'), ('중심', 'NNG'), ('을', 'JKO'), ('잃', 'VV'), ('지', 'EC'), ('않', 'VX'), ('고', 'EC'), ('자신', 'NNG'), ('만', 'JX'), ('의', 'JKG'), ('원칙', 'NNG'), ('을', 'JKO'), ('지키', 'VV'), ('어', 'EC'), ('나가', 'VV'), ('ㄹ', 'ETM'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETM'), ('경지', 'NNG'), ('에', 'JKB'), ('오르', 'VV'), ('는', 'ETM'), ('시기', 'NNP'), ('다', 'EF'), ('.', 'SF'), ('이번', 'NNG'), ('스토브리그에', 'NA'), ('롯데', 'NNP'), ('구단', 'NNP'), ('에', 'JKB'), ('걱정', 'NNG'), ('스럽', 'XSA'), ('ㄴ', 'ETM'), ('일', 'NNG'), ('이', 'JKS'), ('벌어지', 'VV'), ('고', 'EC'), ('있', 'VX'), ('다', 'EF'), ('.', 'SF'), ('그런데', 'MAJ'), ('이대호', 'NNP'), ('는', 'JX'), ('어떤', 'MM'), ('대외', 'NNG'), ('활동', 'NNG'), ('도', 'JX'), ('하', 'VV'), ('지', 'EC'), ('않', 'VX'), ('고', 'EC'), ('침묵', 'NNG'), ('하', 'XSV'), ('며', 'EC'), ('조용히', 'MAG'), ('개인', 'NNG'), ('훈련', 'NNG'), ('에', 'JKB'), ('집중', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('모습', 'NNG'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('불혹', 'NNG'), ('이', 'JKS'), ('되', 'VV'), ('어서', 'EC'), ('이', 'VCP'), ('ㄴ가', 'EF'), ('?', 'SF'), ('지나', 'VV'), ('ㄴ', 'ETM'), ('2017년 1월', 'NNP'), ('24', 'SN'), ('일', 'NNB'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('벌써', 'MAG'), ('5년', 'NNP'), ('의', 'JKG'), ('시간', 'NNG'), ('이', 'JKS'), ('흐르', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('롯데', 'NNP'), ('의', 'JKG'), ('프랜차이즈', 'NNP'), ('스타', 'NNP'), ('이대호', 'NNP'), ('가', 'JKS'), ('일본', 'NNP'), ('프로', 'NNP'), ('야구', 'NNP'), ('미국', 'NNP'), ('메이저', 'NNP'), ('리그', 'NNP'), ('를', 'JKO'), ('거치', 'VV'), ('어', 'EC'), ('고향', 'NNG'), ('팀', 'NNG'), ('롯데', 'NNP'), ('로', 'JKB'), ('돌아오', 'VV'), ('았', 'EP'), ('다', 'EF'), ('.', 'SF'), ('그', 'NP'), ('는', 'JX'), ('‘', 'SS'), ('조선', 'NNP'), ('의', 'JKG'), ('4', 'SN'), ('번', 'NNB'), ('타자', 'NNP'), ('’', 'SS'), ('답', 'XSA'), ('게', 'EC'), ('단숨에', 'MAG'), ('최고', 'NNG'), ('가', 'JKS'), ('되', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('삼성', 'NNP'), ('에서', 'JKB'), ('FA', 'SL'), ('가', 'JKS'), ('되', 'VV'), ('ㄴ', 'ETM'), ('최형우', 'NNP'), ('가', 'JKS'), ('고향', 'NNG'), ('팀', 'NNG'), ('KIA 타이거즈', 'NNP'), ('와', 'JC'), ('4', 'SN'), ('년', 'NNB'), ('계약', 'NNG'), ('을', 'JKO'), ('하', 'VV'), ('면서', 'EC'), ('기록', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETM'), ('총액', 'NNG'), ('100', 'SN'), ('억', 'NR'), ('원', 'NNB'), ('을', 'JKO'), ('훨씬', 'MAG'), ('넘', 'VV'), ('어', 'EC'), ('150', 'SN'), ('억', 'NR'), ('원', 'NNB'), ('에', 'JKB'), ('롯데', 'NNP'), ('와', 'JC'), ('계약', 'NNG'), ('하', 'XSV'), ('았', 'EP'), ('다', 'EF'), ('.', 'SF'), ('당시', 'NNG'), ('인터뷰', 'NNP'), ('에서', 'JKB'), ('이대호', 'NNP'), ('는', 'JX'), ('‘', 'SS'), ('메이저', 'NNP'), ('리그', 'NNP'), ('에서', 'JKB'), ('열심히', 'MAG'), ('노력', 'NNG'), ('하', 'XSV'), ('아', 'EC'), ('꿈', 'NNG'), ('을', 'JKO'), ('이루', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('남은', 'NNP'), ('것', 'NNB'), ('은', 'JX'), ('롯데', 'NNP'), ('로', 'JKB'), ('돌아오', 'VV'), ('아', 'EC'), ('함께', 'MAG'), ('우승', 'NNG'), ('을', 'JKO'), ('하', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('이', 'VCP'), ('다', 'EF'), ('.', 'SF'), ('마지막', 'NNG'), ('소원', 'NNG'), ('이', 'JKS'), ('롯데', 'NNP'), ('의', 'JKG'), ('우승', 'NNP'), ('’', 'SS'), ('이라고', 'JKQ'), ('밝히', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('2001', 'SN'), ('년', 'NNB'), ('롯데', 'NNP'), ('에', 'JKB'), ('2', 'SN'), ('차', 'NNB'), ('1', 'SN'), ('순위', 'NNP'), ('로', 'JKB'), ('입단', 'NNG'), ('하', 'XSV'), ('아', 'EC'), ('2011', 'SN'), ('시즌', 'NNP'), ('까지', 'JX'), ('11', 'SN'), ('시즌', 'NNP'), ('동안', 'NNG'), ('이대호', 'NNP'), ('는', 'JX'), ('무려', 'MAG'), ('225', 'SN'), ('개', 'NNB'), ('의', 'JKG'), ('홈런', 'NNG'), ('을', 'JKO'), ('쏘', 'VV'), ('아', 'EC'), ('올리', 'VV'), ('었', 'EP'), ('다', 'EF'), ('.', 'SF'), ('그리고', 'MAJ'), ('2008', 'SN'), ('~', 'SO'), ('2011', 'SN'), ('시즌', 'NNG'), ('까지', 'JX'), ('4', 'SN'), ('년', 'NNB'), ('연속', 'NNP'), ('롯데', 'NNP'), ('를', 'JKO'), ('포스트', 'NNP'), ('시즌', 'NNP'), ('으로', 'JKB'), ('이끌', 'VV'), ('었', 'EP'), ('으나', 'EC'), ('한국시리즈', 'NNP'), ('우승', 'NNG'), ('을', 'JKO'), ('못하', 'VX'), ('고', 'EC'), ('일본', 'NNP'), ('프로야', 'NNP'), ('구로', 'NNP'), ('떠나', 'VV'), ('았', 'EP'), ('다', 'EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "tokens = komoran.pos(sentence)    # pos-tagging - 형태소 분석\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d4987-73f4-4105-b279-1ddd7bc653a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdf5895-f091-4152-992e-e5e1a421b510",
   "metadata": {},
   "source": [
    "형태소 분석기를 이용하면 각 토큰별로 품사와 함께 토큰화 된 텍스트를 가져올 수 있습니다. 또한 \"롯데 자이언츠\"처럼 중간에 공백이 삽입된 명사도 고유명사로 잘 구분하는 모습을 보여줍니다. \"이대호가\", \"이대호는\"과 같은 단어도 \"이대호\", \"가\", \"이대호\", \"는\"으로 분리해주어 의미 단위로 토큰을 잘 분리하는 모습을 보여줍니다.\n",
    "\n",
    "하지만 형태소 분석기는 신조어나 고유 명사에 상당히 취약한 모습을 보이기도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558fb1ab-98af-4686-91ed-8b5a754fe918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SSG', 'SL'), ('랜더스의', 'NA'), ('추신수', 'NNP'), ('선수', 'NNG'), ('가', 'JKS'), ('NC 다이노스', 'NNP'), ('의', 'JKG'), ('안우', 'NNP'), ('진', 'NNP'), ('선수', 'NNG'), ('를', 'JKO'), ('상대로', 'NNP'), ('홈런', 'NNG'), ('을', 'JKO'), ('치', 'VV'), ('었', 'EP'), ('습니다', 'EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"SSG 랜더스의 추신수 선수가 NC 다이노스의 안우진 선수를 상대로 홈런을 쳤습니다.\"\n",
    "print(komoran.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb5586-69a2-4d83-bb32-05460b0fdc81",
   "metadata": {},
   "source": [
    "\"SSG\", \"랜더스\", \"안우진\" 등의 고유 명사를 NNP로 잡아내지 못하는 모습을 보입니다. 이러한 형태소 분석기의 한계점은 고유 명사를 직접 지정하는 사용자 사전 기능으로 극복할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9b48ae-79ec-4531-af66-66a71de1a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 고유 명사 직접 지정해주기\n",
    "komoran = Komoran(userdic=\"./data/user.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109af523-05eb-4a01-8414-d8fd2eb8d564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SSG', 'NNP'), ('랜더스', 'NNP'), ('의', 'JKG'), ('추신수', 'NNP'), ('선수', 'NNG'), ('가', 'JKS'), ('NC', 'NNP'), ('다이노스', 'NNP'), ('의', 'JKG'), ('안우진', 'NNP'), ('선수', 'NNG'), ('를', 'JKO'), ('상대로', 'NNP'), ('홈런', 'NNG'), ('을', 'JKO'), ('치', 'VV'), ('었', 'EP'), ('습니다', 'EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "print(komoran.pos(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495b5ab-2cad-4a08-9570-712b0cbf12dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a349110-e507-4a92-86c0-7608ec3c6f89",
   "metadata": {},
   "source": [
    "## 전체 데이터 셋 토크나이즈\n",
    "\n",
    "웹 크롤링 시간에 정규 표현식을 이용해서 전처리 했었던 데이터 셋을 tokenize 해보겠습니다. 한번 전체 데이터 셋 중 1000개만 토큰화하여 결과를 CSV 파일에 써보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f4864c0-e5e8-457c-8ed5-c38eb068f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    try:\n",
    "        tokens = komoran.pos(sentence)\n",
    "        nouns = [token for token, tag in tokens if tag in (\"NNP\", \"NNG\")]\n",
    "        return nouns\n",
    "        #return komoran.pos(sentence)\n",
    "    except:\n",
    "        print(\"예외!\", sentence)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827cf8e6-3d4f-40ba-b112-3047d1dc582d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSG', '랜더스', '추신수', '선수', 'NC', '다이노스', '안우진', '선수', '상대로', '홈런']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1a1277-cd28-4f7a-bfeb-551d1be9f3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/baseball_preprocessed.csv\", encoding=\"utf-8\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e61105-63cb-405c-b42b-06e71a833073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_df = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "347164c1-2dc6-4e9a-9f66-e30d4e94b518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▎                                                          | 2378/10000 [00:56<03:21, 37.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예외! \"대호야, 고마 막 쎄리뿌라.\"롯데 이대호(40)가 KBO리그 역대 두 번째 은퇴투어 주인공이 됐다. KBO는 14일 해당 사실을 공식 발표했다. 이대호는 \"9개 구단과 KBO의 배려에 진심으로 감사 드린다. 사인회를 진행하고 싶다. 나 혼자 하는 은퇴식이 아니다. 팬들과 함께 하는 행사가 되면 좋겠다\"라고 했다.그동안 KBO리그 은퇴투어는 공식적으로 '국민타자' 이승엽이 유일했다. 2017시즌 삼성을 제외한 나머지 9개 구단이 삼성과의 마지막 홈 시리즈에 맞춰 은퇴투어를 개최했다. 서로 선물도 주고 받았고, 기념행사를 열었다. 이후 은퇴투어의 자격 요건을 놓고 팬들 사이에서 의견이 분분했다. 첫 번째 선수가 국민타자라서 은퇴투어의 격이 너무 올라간 상태였다. 이후 선수들끼리 자발적으로 몇몇 선수가 은퇴할 때 격려하는 행사만 있었을 뿐이다. 그러나 이대호라면 은퇴투어 자격은 충분하다. KBO리그와 롯데 역사에 한 획을 그은 타자인 건 분명하다. 이대호는 일찌감치 올 시즌을 끝으로 은퇴를 선언했고, 스프링캠프 인터뷰서는 그저 팬들에게 사인해드릴 기회만 생겼으면 좋겠다고 희망하기도 했다. 어쨌든 판이 깔렸으니 이대호의 2022시즌에 관심이 쏠린다.'1호 은퇴투어' 이승엽도 이대호의 은퇴투어를 크게 반겼다. 자신의 인스타그램에 \"은퇴투어 확정, KBO와 10개 구단의 결정에 감사드립니다. 대호야, 올 시즌 후회 없이 고마 막 쎄리뿌라, 마무리 잘하자\"라고 적었다. 그러면서 \"여러분도 이대호 선수에게 많은 응원 부탁 드립니다. 기분 조~타\"라고 했다.과거 롯데에서 한솥밥을 먹은 황재균(KT)도 자신의 인스타그램에 \"은퇴투어를 하는 게 정말 대단한것인데 같은 야구선수로서 멋있어요👍🏻 긴 시간동안 고생많았어요. 마지막 시즌은 즐겁게\"라고 적었다.    [이대호와 이승엽, 이대호와 황재균. 사진 = 마이데일리 사진 DB](김진성 기자 kkomag@mydaily.co.kr)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▎                                          | 4457/10000 [01:47<01:54, 48.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예외! 🎧 아래 주소로 접속하시면 음성으로 기사를 들을 수 있습니다.[ https://news.sbs.co.kr/n/?id=N1006727828 ] [골룸] 야구에 산다 제77구 : '승리 공식' SSG 김택형 인터뷰!올 시즌 프로야구부터 스트라이크존이 넓어졌습니다.개막 직후 경기에서는 투수와 타자 모두 넓어진 스트라이크존을 낯설어했었는데요.역대급 투고타저를 기록하던 첫 열흘 경기와는 달리, 최근 2주 동안은 한층 안정된 모습을 보여주고 있습니다.한편, 이번 시즌 롯데가 압도적으로 역대급 삼진율을 보여주고 있습니다.그 기록의 중심에 서있는 한동희를 분석해봅니다.야구에 산다 제77구에서는 SSG 랜더스 김택형과 인터뷰 진행합니다.팀의 승리 공식으로 자리매김한 김택형은 범상치 않은 인터뷰 실력으로 '토크 천재'의 면모를 보여줬습니다.자세한 이야기는 오디오로 들어보세요!녹음 시점: 4월 25일진행: 정우영 캐스터, 이성훈 기자 | 전화연결: 김택형\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▍                             | 6153/10000 [02:29<01:26, 44.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예외! nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████▏                     | 7175/10000 [02:54<00:47, 59.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예외! nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [04:04<00:00, 40.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "sampled_df[\"nouns\"] = sampled_df[\"content\"].progress_apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d170f-5a05-4e28-8262-a80a9f7efc00",
   "metadata": {},
   "source": [
    "## 명사만 추출한 뒤 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c35ba80-7f17-404a-aa1c-ff7ff6fc97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[[\"nouns\"]].to_csv(\"./data/sampled_baseball_nouns.tsv\", sep=\"\\t\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8c8cf-83ed-47a7-a051-e4d11f2c6149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cf3cf25-631e-42b3-a97f-26546f17b10c",
   "metadata": {},
   "source": [
    "## 정리\n",
    "이번 챕터에서는 python에서 자연어를 처리하기 위한 첫 스텝인 토큰화에 대해서 알아보았습니다. 그리고 토큰화 방식 중에 하나인 형태소 기반의 토큰화를 알아보았고, konlpy Komoran을 이용해서 토큰화를 해보았습니다.\n",
    "\n",
    "한국어 형태소 분석기에는 Komoran만 있는 것은 아닙니다. 속도 측면에서는 Mecab, 정확도 측면에서는 Khaiii라는 프로젝트가 우수합니다만, 각각 설치 및 사용자 사전 등록이 까다로워서 수업 자료에 사용하지는 않았습니다. 실제 프로젝트를 진행할 때 Komoran의 성능이 아쉽다면 선택해볼만 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec3e2e7-e2ba-4403-9e70-085bb5ad26a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
